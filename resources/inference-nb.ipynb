{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9510375,"sourceType":"datasetVersion","datasetId":5788903}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"!pip install huggingface_hub\nfrom huggingface_hub import login\n\napi_token = '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'\nlogin(api_token)","metadata":{"execution":{"iopub.status.busy":"2024-10-06T12:50:05.802612Z","iopub.execute_input":"2024-10-06T12:50:05.803490Z","iopub.status.idle":"2024-10-06T12:50:18.436791Z","shell.execute_reply.started":"2024-10-06T12:50:05.803447Z","shell.execute_reply":"2024-10-06T12:50:18.435798Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.8.30)\nThe token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install nltk","metadata":{"execution":{"iopub.status.busy":"2024-10-06T12:50:38.300991Z","iopub.execute_input":"2024-10-06T12:50:38.301369Z","iopub.status.idle":"2024-10-06T12:50:49.623888Z","shell.execute_reply.started":"2024-10-06T12:50:38.301333Z","shell.execute_reply":"2024-10-06T12:50:49.622959Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\nimport nltk\nfrom nltk.corpus import wordnet as wn\nimport re\n# Make sure to download the required NLTK data\nnltk.download('wordnet')\nnltk.download('omw-1.4')\n\ndef get_synonym(word):\n    synonyms = wn.synsets(word)\n    if synonyms:\n        words = set(chain.from_iterable([syn.lemma_names() for syn in synonyms]))\n        words.discard(word)  # Avoid returning the same word\n        if words:\n            return random.choice(list(words))\n    return word\n\ndef augment_text(text):\n    words = text.split()\n    augmented_text = []\n    for word in words:\n        if random.random() < 0.3:  # 30% chance of replacing a word\n            augmented_text.append(get_synonym(word))\n        else:\n            augmented_text.append(word)\n    return ' '.join(augmented_text)\n\ndef augment_dataframe(df, fraction):\n    to_augment = df.sample(frac=fraction).index\n    df['text'] = df['text'].apply(lambda x: augment_text(x) if x in to_augment else x)\n    return df\n\nclass TextCleaner():\n    def __init__(self):\n        pass\n    \n    def clean_text(self, text):\n        text = (str(text)).lower()\n        text = re.sub(r'<.*?>', '', text)\n        text = re.sub(r'http\\S+', '', text)\n        text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n        text = re.sub(r\"\\s+\", \" \", text).strip()\n        return text\n\ncleaner = TextCleaner()","metadata":{"execution":{"iopub.status.busy":"2024-10-06T12:51:00.195360Z","iopub.execute_input":"2024-10-06T12:51:00.195785Z","iopub.status.idle":"2024-10-06T12:51:01.533612Z","shell.execute_reply.started":"2024-10-06T12:51:00.195744Z","shell.execute_reply":"2024-10-06T12:51:01.532665Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom transformers import AutoTokenizer, RobertaForSequenceClassification\nfrom datasets import Dataset\n\n# Define your model repository name\nmodel_name = \"pilotj/roberta-base-v1\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = RobertaForSequenceClassification.from_pretrained(model_name)\n\nmodel.to(\"cuda:0\")\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Load your test data\ntest_data = pd.read_csv(\"/kaggle/input/fibe-dataset-v2/dataset/test.csv\" , encoding='latin-1')  # Replace with your actual test data file path\ntest_data['text'] = test_data['text'].apply(cleaner.clean_text)\naugment_dataframe(test_data, fraction = 0.30)\n\ntest_dataset = Dataset.from_pandas(test_data[['text']])\n\ndef preprocess_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True, padding='max_length', max_length=512)\n\ntest_inputs = test_dataset.map(preprocess_function, batched=True, batch_size=64)\n\ntest_inputs.set_format(type='torch', columns=['input_ids', 'attention_mask'])\ntest_inputs","metadata":{"execution":{"iopub.status.busy":"2024-10-06T12:54:39.919229Z","iopub.execute_input":"2024-10-06T12:54:39.919695Z","iopub.status.idle":"2024-10-06T12:57:37.960480Z","shell.execute_reply.started":"2024-10-06T12:54:39.919636Z","shell.execute_reply":"2024-10-06T12:57:37.959568Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/174382 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1e153e326274fba9412d27cb5e55364"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'input_ids', 'attention_mask'],\n    num_rows: 174382\n})"},"metadata":{}}]},{"cell_type":"code","source":"train_set = pd.read_csv(\"/kaggle/input/fibe-dataset-v2/dataset/train.csv\", encoding = 'latin-1')\ntargets_list = (train_set[\"target\"].unique()).tolist()","metadata":{"execution":{"iopub.status.busy":"2024-10-06T12:57:50.705835Z","iopub.execute_input":"2024-10-06T12:57:50.706253Z","iopub.status.idle":"2024-10-06T12:58:15.327381Z","shell.execute_reply.started":"2024-10-06T12:57:50.706211Z","shell.execute_reply":"2024-10-06T12:58:15.326544Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"targets_list_dum = ['academic interests', 'arts and culture', 'automotives', 'books and literature', 'business and finance', 'careers', 'family and relationships', 'food and drinks', 'health', 'healthy living', 'hobbies and interests', 'home and garden', 'movies', 'music and audio', 'news and politics', 'personal finance', 'pets', 'pharmaceuticals, conditions, and symptoms', 'real estate', 'shopping', 'sports', 'style and fashion', 'technology and computing', 'television', 'travel', 'video gaming']\ntargets_list_dum == targets_list","metadata":{"execution":{"iopub.status.busy":"2024-10-06T12:59:14.853555Z","iopub.execute_input":"2024-10-06T12:59:14.854264Z","iopub.status.idle":"2024-10-06T12:59:14.861229Z","shell.execute_reply.started":"2024-10-06T12:59:14.854225Z","shell.execute_reply":"2024-10-06T12:59:14.860303Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport torch\n\n# Create empty dataframe\nresult = pd.DataFrame(columns=[\"target\", \"Index\"])\n\ndef inference_fn(test_inputs, test_data, model, result, batch):\n    # Wrap model in DataParallel\n    model = torch.nn.DataParallel(model).to(\"cuda:0\")  # Move model to the first GPU\n\n    for i in range(0, len(test_data), batch):\n        indexes = test_data[i:i+batch]['Index'].tolist()\n        input_ids = test_inputs['input_ids'][i:i+batch].to(\"cuda:0\")\n        attention_mask = test_inputs['attention_mask'][i:i+batch].to(\"cuda:0\")\n        \n        # Perform inference\n        with torch.no_grad():\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n\n        # Get the predicted class labels\n        predictions = torch.argmax(outputs.logits, dim=1)\n\n        # Convert predictions to a list\n        predicted_labels = predictions.cpu().numpy().tolist()\n        preds = [targets_list[i] for i in predicted_labels]\n\n        batch_df = pd.DataFrame({\n            'target': preds,\n            'Index': indexes\n        })\n        result = pd.concat([result, batch_df], ignore_index=True)\n\n        if i % (batch * 4) == 0:\n            print(f\"{i} done.\")\n\n    return result\n","metadata":{"execution":{"iopub.status.busy":"2024-10-06T12:59:19.595740Z","iopub.execute_input":"2024-10-06T12:59:19.596603Z","iopub.status.idle":"2024-10-06T12:59:19.607648Z","shell.execute_reply.started":"2024-10-06T12:59:19.596563Z","shell.execute_reply":"2024-10-06T12:59:19.606627Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"result_df = inference_fn(test_inputs, test_data, model, result, batch=512)","metadata":{"execution":{"iopub.status.busy":"2024-10-06T12:59:30.998859Z","iopub.execute_input":"2024-10-06T12:59:30.999248Z","iopub.status.idle":"2024-10-06T13:53:16.747758Z","shell.execute_reply.started":"2024-10-06T12:59:30.999214Z","shell.execute_reply":"2024-10-06T13:53:16.746837Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"0 done.\n2048 done.\n4096 done.\n6144 done.\n8192 done.\n10240 done.\n12288 done.\n14336 done.\n16384 done.\n18432 done.\n20480 done.\n22528 done.\n24576 done.\n26624 done.\n28672 done.\n30720 done.\n32768 done.\n34816 done.\n36864 done.\n38912 done.\n40960 done.\n43008 done.\n45056 done.\n47104 done.\n49152 done.\n51200 done.\n53248 done.\n55296 done.\n57344 done.\n59392 done.\n61440 done.\n63488 done.\n65536 done.\n67584 done.\n69632 done.\n71680 done.\n73728 done.\n75776 done.\n77824 done.\n79872 done.\n81920 done.\n83968 done.\n86016 done.\n88064 done.\n90112 done.\n92160 done.\n94208 done.\n96256 done.\n98304 done.\n100352 done.\n102400 done.\n104448 done.\n106496 done.\n108544 done.\n110592 done.\n112640 done.\n114688 done.\n116736 done.\n118784 done.\n120832 done.\n122880 done.\n124928 done.\n126976 done.\n129024 done.\n131072 done.\n133120 done.\n135168 done.\n137216 done.\n139264 done.\n141312 done.\n143360 done.\n145408 done.\n147456 done.\n149504 done.\n151552 done.\n153600 done.\n155648 done.\n157696 done.\n159744 done.\n161792 done.\n163840 done.\n165888 done.\n167936 done.\n169984 done.\n172032 done.\n174080 done.\n","output_type":"stream"}]},{"cell_type":"code","source":"result_df.to_csv(\"submission_final_fibe.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:53:27.855062Z","iopub.execute_input":"2024-10-06T13:53:27.855481Z","iopub.status.idle":"2024-10-06T13:53:28.207553Z","shell.execute_reply.started":"2024-10-06T13:53:27.855442Z","shell.execute_reply":"2024-10-06T13:53:28.206681Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}